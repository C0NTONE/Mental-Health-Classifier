{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/willmsc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Must include these two lines for the code to compile initially\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text      label\n",
      "0      dear american teens question dutch person hear...    Healthy\n",
      "1      nothing look forward lifei dont many reasons k...  Unhealthy\n",
      "2      music recommendations im looking expand playli...    Healthy\n",
      "3      im done trying feel betterthe reason im still ...  Unhealthy\n",
      "4      worried  year old girl subject domestic physic...  Unhealthy\n",
      "...                                                  ...        ...\n",
      "27972  posting everyday people stop caring  religion ...    Healthy\n",
      "27973  okay definetly need hear guys opinion ive pret...    Healthy\n",
      "27974  cant get dog think ill kill myselfthe last thi...  Unhealthy\n",
      "27975  whats point princess bridei really think like ...  Unhealthy\n",
      "27976  got nudes person might might know snapchat do ...    Healthy\n",
      "\n",
      "[27977 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('mental_health.csv', sep=',', quoting=csv.QUOTE_NONE)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(message):\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72566\n",
      "CountVectorizer(analyzer=<function split_into_tokens at 0x7f45fcb23378>,\n",
      "                binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "bag_of_words =  CountVectorizer(analyzer=split_into_tokens).fit(df['text'])\n",
    "print(len(bag_of_words.vocabulary_))\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(text_train, text_test, bow_transformer):\n",
    "    \"\"\"\n",
    "    Preprocesses the training and testing text by transforming them to their TF-IDF representation.\n",
    "\n",
    "    Args:\n",
    "        text_train: A list of training text.\n",
    "        text_test: A list of testing text.\n",
    "        bow_transformer: A bag-of-words (BOW) transformer fitted to the training data.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the training text's TF-IDF representation and the testing text's TF-IDF representation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform the training text using the bag-of-words (BOW) transformer\n",
    "    train_text_bow = bow_transformer.transform(text_train)\n",
    "\n",
    "    # Fit a Term Frequency-Inverse Document Frequency (TF-IDF) transformer to the training text's BOW representation\n",
    "    train_tfidf_transformer = TfidfTransformer().fit(train_text_bow)\n",
    "\n",
    "    # Transform the training text to their TF-IDF representation\n",
    "    train_text_tfidf = train_tfidf_transformer.transform(train_text_bow)\n",
    "\n",
    "    # Transform the testing text using the bag-of-words (BOW) transformer\n",
    "    test_text_bow = bow_transformer.transform(text_test)\n",
    "    \n",
    "    # Fit a Term Frequency-Inverse Document Frequency (TF-IDF) transformer to the testing text's BOW representation\n",
    "    test_tfidf_transformer = TfidfTransformer().fit(test_text_bow)\n",
    "\n",
    "    # Transform the testing text to their TF-IDF representation\n",
    "    test_text_tfidf = test_tfidf_transformer.transform(test_text_bow)\n",
    "\n",
    "    # Return a tuple containing the training and testing text's TF-IDF representations\n",
    "    return (train_text_tfidf, test_text_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, label_train, label_test = \\\n",
    "    train_test_split(df['text'], df['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<22381x72566 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1244869 stored elements in Compressed Sparse Row format>, <5596x72566 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 312950 stored elements in Compressed Sparse Row format>)\n"
     ]
    }
   ],
   "source": [
    "#This is the line in which the Naive Bayes model is created and fed the answers for the 'training' data\n",
    "#In essence, it is memorizing all the answers to each of the elements of the training data so when you enter a piece of testing data, it will determine the most likely (\"closest\") element in the training data, and return that element's label\n",
    "#So it's pretty simple and might not perform that well, but it gives us a baseline, and if we are able to beat it, we will know our model is better than strict memorization!\n",
    "data = prepare_data(text_train, text_test,bag_of_words)\n",
    "\n",
    "mental_health_classifier = MultinomialNB().fit(data[0], label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello my day is great\"\n",
    "answer = \"Healthy\"\n",
    "new_data = bag_of_words.transform(pd.DataFrame({\"text\":[text], \"label\":[answer]})[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthy']\n"
     ]
    }
   ],
   "source": [
    "predictions = mental_health_classifier.predict(new_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18291    its selfish thing anyone dothats stepmother sa...\n",
      "10904    need helpi know anymore  years since ive talke...\n",
      "13391    im giving horny life aight nerds aint chief ho...\n",
      "18399    need advicei want kill girl manipulates left b...\n",
      "19487    helpive trying get contact therapist little we...\n",
      "                               ...                        \n",
      "3779     cant wake upi suicidal lately super hard trip ...\n",
      "27958    bees smol one bee swarm one giant bee heck one...\n",
      "18267    im doneim done everything im tired living earl...\n",
      "4619     suicidal thoughts getting worseif see post acc...\n",
      "1687     dead luckyi cant help think died lucky theres ...\n",
      "Name: text, Length: 5596, dtype: object\n",
      "18291    Unhealthy\n",
      "10904    Unhealthy\n",
      "13391      Healthy\n",
      "18399    Unhealthy\n",
      "19487    Unhealthy\n",
      "           ...    \n",
      "3779     Unhealthy\n",
      "27958      Healthy\n",
      "18267    Unhealthy\n",
      "4619     Unhealthy\n",
      "1687     Unhealthy\n",
      "Name: label, Length: 5596, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#If you are curious what the actual values/labels are, you can print them out here\n",
    "print(text_test)\n",
    "print(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unhealthy' 'Unhealthy' 'Healthy' ... 'Unhealthy' 'Unhealthy' 'Unhealthy']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8422087205146533\n",
      "Recall 0.7043048694424842\n",
      "Precision 0.9779519843214111\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', accuracy_score(label_test, predictions))\n",
    "print('Recall', recall_score(label_test, predictions,average=\"binary\", pos_label = \"Healthy\"))\n",
    "print('Precision', precision_score(label_test, predictions,average=\"binary\", pos_label = \"Healthy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
