{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf331f96",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ec76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bloomgardeni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Must include these two lines for the code to compile initially\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f4567e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text      label\n",
      "0      dear american teens question dutch person hear...    Healthy\n",
      "1      nothing look forward lifei dont many reasons k...  Unhealthy\n",
      "2      music recommendations im looking expand playli...    Healthy\n",
      "3      im done trying feel betterthe reason im still ...  Unhealthy\n",
      "4      worried  year old girl subject domestic physic...  Unhealthy\n",
      "...                                                  ...        ...\n",
      "27972  posting everyday people stop caring  religion ...    Healthy\n",
      "27973  okay definetly need hear guys opinion ive pret...    Healthy\n",
      "27974  cant get dog think ill kill myselfthe last thi...  Unhealthy\n",
      "27975  whats point princess bridei really think like ...  Unhealthy\n",
      "27976  got nudes person might might know snapchat do ...    Healthy\n",
      "\n",
      "[27977 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Simply puts the data into a dataframe\n",
    "df = pd.read_csv('mental_health.csv', sep=',', quoting=csv.QUOTE_NONE)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e836ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple tokenizer since the data is already lemmized!\n",
    "def split_into_tokens(message):\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6702a42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72566\n",
      "CountVectorizer(analyzer=<function split_into_tokens at 0x7fa9411bb130>)\n"
     ]
    }
   ],
   "source": [
    "#once you create the bag of words, you don't have to do it again, so I removed it from the prepare_data function\n",
    "bag_of_words =  CountVectorizer(analyzer=split_into_tokens).fit(df['text'])\n",
    "print(len(bag_of_words.vocabulary_))\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2386297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is by far the most dense cell, I got chatgpt to comment it!\n",
    "#I hope this makes it a little more readable, it's a bit different that what we did with out lab!\n",
    "#Also don't worry, all the code is mine, only the comments are plagerized :)\n",
    "\n",
    "def prepare_data(text_train, text_test, bow_transformer):\n",
    "    \"\"\"\n",
    "    Preprocesses the training and testing text by transforming them to their TF-IDF representation.\n",
    "\n",
    "    Args:\n",
    "        text_train: A list of training text.\n",
    "        text_test: A list of testing text.\n",
    "        bow_transformer: A bag-of-words (BOW) transformer fitted to the training data.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the training text's TF-IDF representation and the testing text's TF-IDF representation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform the training text using the bag-of-words (BOW) transformer\n",
    "    train_text_bow = bow_transformer.transform(text_train)\n",
    "\n",
    "    # Fit a Term Frequency-Inverse Document Frequency (TF-IDF) transformer to the training text's BOW representation\n",
    "    train_tfidf_transformer = TfidfTransformer().fit(train_text_bow)\n",
    "\n",
    "    # Transform the training text to their TF-IDF representation\n",
    "    train_text_tfidf = train_tfidf_transformer.transform(train_text_bow)\n",
    "\n",
    "    # Transform the testing text using the bag-of-words (BOW) transformer\n",
    "    test_text_bow = bow_transformer.transform(text_test)\n",
    "\n",
    "    # Fit a Term Frequency-Inverse Document Frequency (TF-IDF) transformer to the testing text's BOW representation\n",
    "    test_tfidf_transformer = TfidfTransformer().fit(test_text_bow)\n",
    "\n",
    "    # Transform the testing text to their TF-IDF representation\n",
    "    test_text_tfidf = test_tfidf_transformer.transform(test_text_bow)\n",
    "\n",
    "    # Return a tuple containing the training and testing text's TF-IDF representations\n",
    "    return (train_text_tfidf, test_text_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a7bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fiddle with this to change the test-train split\n",
    "text_train, text_test, label_train, label_test = \\\n",
    "    train_test_split(df['text'], df['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45da7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the line in which the Naive Bayes model is created and fed the answers for the 'training' data\n",
    "#In essence, it is memorizing all the answers to each of the elements of the training data so when you enter a piece of testing data, it will determine the most likely (\"closest\") element in the training data, and return that element's label\n",
    "#So it's pretty simple and might not perform that well, but it gives us a baseline, and if we are able to beat it, we will know our model is better than strict memorization!\n",
    "data = prepare_data(text_train, text_test,bag_of_words)\n",
    "mental_health_classifier = MultinomialNB().fit(data[0], label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58c8c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line simply generates the predicted label for all the elements of the training data\n",
    "predictions = mental_health_classifier.predict(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85498ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18988    tender beautifully crafted production delved d...\n",
      "17925    compare movie industry ocean tendencies observ...\n",
      "960      losing fighti feel worthless alone want burden...\n",
      "11575    want future im tiredi want live long brain ada...\n",
      "14483    millionaire happy family apparent reason depre...\n",
      "                               ...                        \n",
      "4665     ji trnka made last animated short indictment t...\n",
      "8351     youre poor spend two hours finding coupon code...\n",
      "14913    fear break broke meive thought redflag years d...\n",
      "19977    know want kill myself nearly kill myselfi feel...\n",
      "11978    im glad exist whoevers reading this thats want...\n",
      "Name: text, Length: 5596, dtype: object\n",
      "18988      Healthy\n",
      "17925      Healthy\n",
      "960      Unhealthy\n",
      "11575    Unhealthy\n",
      "14483    Unhealthy\n",
      "           ...    \n",
      "4665       Healthy\n",
      "8351       Healthy\n",
      "14913    Unhealthy\n",
      "19977    Unhealthy\n",
      "11978      Healthy\n",
      "Name: label, Length: 5596, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#If you are curious what the actual values/labels are, you can print them out here\n",
    "print(text_test)\n",
    "print(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23b4f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthy' 'Healthy' 'Unhealthy' ... 'Unhealthy' 'Unhealthy' 'Unhealthy']\n"
     ]
    }
   ],
   "source": [
    "#And then you can manually compare them to the predictions\n",
    "print(predictions)\n",
    "#As you can see, it's kinda alright, but not perfect, but good enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6adb9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8402430307362402\n",
      "Recall 0.6979534227240649\n",
      "Precision 0.9811507936507936\n"
     ]
    }
   ],
   "source": [
    "#Since I also imported a bunch of accuracy functions, you can use them here to check the success rate!\n",
    "print('Accuracy', accuracy_score(label_test, predictions))\n",
    "print('Recall', recall_score(label_test, predictions,average=\"binary\", pos_label = \"Healthy\"))\n",
    "print('Precision', precision_score(label_test, predictions,average=\"binary\", pos_label = \"Healthy\"))\n",
    "#Feel free to add more if you feel like!\n",
    "#Also, for our presentation, if you have time, you can graph how the data looks, it might be cool\n",
    "#There are a lot of ways you can go about that, so I'll let you determine what you want to do!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental_health_env",
   "language": "python",
   "name": "mental_health_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
